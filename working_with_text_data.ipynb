{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [\"Some say the world will end in fire,\",\n",
    "     \"Some say in ice.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#implementing bag_of_words model for text data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()\n",
    "vect.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'end': 0,\n",
       " 'fire': 1,\n",
       " 'ice': 2,\n",
       " 'in': 3,\n",
       " 'say': 4,\n",
       " 'some': 5,\n",
       " 'the': 6,\n",
       " 'will': 7,\n",
       " 'world': 8}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bag_of_words =vect.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x9 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 12 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bag_of_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 1, 1, 1, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['end', 'fire', 'in', 'say', 'some', 'the', 'will', 'world'],\n",
       "       dtype='<U5'), array(['ice', 'in', 'say', 'some'], dtype='<U5')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.inverse_transform(X_bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using tf-idf (term frequency- inverse document frequency)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_vect = TfidfVectorizer()\n",
    "tf_vect.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.39 0.39 0.   0.28 0.28 0.28 0.39 0.39 0.39]\n",
      " [0.   0.   0.63 0.45 0.45 0.45 0.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "\n",
    "print(tf_vect.transform(X).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(2, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Ngrams method\n",
    "\n",
    "bgrams = CountVectorizer(ngram_range=(2,2))\n",
    "\n",
    "bgrams.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'end in': 0,\n",
       " 'in fire': 1,\n",
       " 'in ice': 2,\n",
       " 'say in': 3,\n",
       " 'say the': 4,\n",
       " 'some say': 5,\n",
       " 'the world': 6,\n",
       " 'will end': 7,\n",
       " 'world will': 8}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgrams.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 1, 1, 0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgrams.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_grams = CountVectorizer(ngram_range=(1,2))\n",
    "n_grams.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'end': 0,\n",
       " 'end in': 1,\n",
       " 'fire': 2,\n",
       " 'ice': 3,\n",
       " 'in': 4,\n",
       " 'in fire': 5,\n",
       " 'in ice': 6,\n",
       " 'say': 7,\n",
       " 'say in': 8,\n",
       " 'say the': 9,\n",
       " 'some': 10,\n",
       " 'some say': 11,\n",
       " 'the': 12,\n",
       " 'the world': 13,\n",
       " 'will': 14,\n",
       " 'will end': 15,\n",
       " 'world': 16,\n",
       " 'world will': 17}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_grams.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['end',\n",
       " 'end in',\n",
       " 'fire',\n",
       " 'ice',\n",
       " 'in',\n",
       " 'in fire',\n",
       " 'in ice',\n",
       " 'say',\n",
       " 'say in',\n",
       " 'say the',\n",
       " 'some',\n",
       " 'some say',\n",
       " 'the',\n",
       " 'the world',\n",
       " 'will',\n",
       " 'will end',\n",
       " 'world',\n",
       " 'world will']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_grams.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_grams.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# character vectorsier\n",
    "X = [\"Some say the world will end in fire,\",\n",
    "     \"Some say in ice.\"]\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "char_vect = CountVectorizer(ngram_range=(1,2), analyzer=\"char\")\n",
    "char_vect.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', ' e', ' f', ' i', ' s', ' t', ' w', ',', '.', 'a', 'ay', 'c', 'ce', 'd', 'd ', 'e', 'e ', 'e,', 'e.', 'en', 'f', 'fi', 'h', 'he', 'i', 'ic', 'il', 'in', 'ir', 'l', 'l ', 'ld', 'll', 'm', 'me', 'n', 'n ', 'nd', 'o', 'om', 'or', 'r', 're', 'rl', 's', 'sa', 'so', 't', 'th', 'w', 'wi', 'wo', 'y', 'y ']\n"
     ]
    }
   ],
   "source": [
    "print(char_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "zen = \"\"\"Beautiful is better than ugly.\n",
    "Explicit is better than implicit.\n",
    "Simple is better than complex.\n",
    "Complex is better than complicated.\n",
    "Flat is better than nested.\n",
    "Sparse is better than dense.\n",
    "Readability counts.\n",
    "Special cases aren't special enough to break the rules.\n",
    "Although practicality beats purity.\n",
    "Errors should never pass silently.\n",
    "Unless explicitly silenced.\n",
    "In the face of ambiguity, refuse the temptation to guess.\n",
    "There should be one-- and preferably only one --obvious way to do it.\n",
    "Although that way may not be obvious at first unless you're Dutch.\n",
    "Now is better than never.\n",
    "Although never is often better than *right* now.\n",
    "If the implementation is hard to explain, it's a bad idea.\n",
    "If the implementation is easy to explain, it may be a good idea.\n",
    "Namespaces are one honking great idea -- let's do more of those!\"\"\"\n",
    "\n",
    "lines = [line for line in zen.split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Beautiful is better than ugly.',\n",
       " 'Explicit is better than implicit.',\n",
       " 'Simple is better than complex.',\n",
       " 'Complex is better than complicated.',\n",
       " 'Flat is better than nested.',\n",
       " 'Sparse is better than dense.',\n",
       " 'Readability counts.',\n",
       " \"Special cases aren't special enough to break the rules.\",\n",
       " 'Although practicality beats purity.',\n",
       " 'Errors should never pass silently.',\n",
       " 'Unless explicitly silenced.',\n",
       " 'In the face of ambiguity, refuse the temptation to guess.',\n",
       " 'There should be one-- and preferably only one --obvious way to do it.',\n",
       " \"Although that way may not be obvious at first unless you're Dutch.\",\n",
       " 'Now is better than never.',\n",
       " 'Although never is often better than *right* now.',\n",
       " \"If the implementation is hard to explain, it's a bad idea.\",\n",
       " 'If the implementation is easy to explain, it may be a good idea.',\n",
       " \"Namespaces are one honking great idea -- let's do more of those!\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x9 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 12 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect1 = TfidfVectorizer()\n",
    "vect1.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.39166832 0.39166832 0.         0.27867523 0.27867523 0.27867523\n",
      "  0.39166832 0.39166832 0.39166832]\n",
      " [0.         0.         0.63009934 0.44832087 0.44832087 0.44832087\n",
      "  0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "counts = vect1.transform(X).toarray()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'end': 0,\n",
       " 'fire': 1,\n",
       " 'ice': 2,\n",
       " 'in': 3,\n",
       " 'say': 4,\n",
       " 'some': 5,\n",
       " 'the': 6,\n",
       " 'will': 7,\n",
       " 'world': 8}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect1.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most common token index :  3\n",
      "most common token is :  in\n"
     ]
    }
   ],
   "source": [
    "most_common = np.argmax(counts.sum(axis=0))\n",
    "print('most common token index : ',most_common)\n",
    "print('most common token is : ',vect1.get_feature_names()[most_common])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(3, 3), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting tri_gram\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect2 = CountVectorizer(ngram_range=(3,3))\n",
    "vect2.fit(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'although never is': 0,\n",
       " 'although practicality beats': 1,\n",
       " 'although that way': 2,\n",
       " 'ambiguity refuse the': 3,\n",
       " 'and preferably only': 4,\n",
       " 'are one honking': 5,\n",
       " 'aren special enough': 6,\n",
       " 'at first unless': 7,\n",
       " 'be good idea': 8,\n",
       " 'be obvious at': 9,\n",
       " 'be one and': 10,\n",
       " 'beautiful is better': 11,\n",
       " 'better than complex': 12,\n",
       " 'better than complicated': 13,\n",
       " 'better than dense': 14,\n",
       " 'better than implicit': 15,\n",
       " 'better than nested': 16,\n",
       " 'better than never': 17,\n",
       " 'better than right': 18,\n",
       " 'better than ugly': 19,\n",
       " 'break the rules': 20,\n",
       " 'cases aren special': 21,\n",
       " 'complex is better': 22,\n",
       " 'do more of': 23,\n",
       " 'easy to explain': 24,\n",
       " 'enough to break': 25,\n",
       " 'errors should never': 26,\n",
       " 'explain it bad': 27,\n",
       " 'explain it may': 28,\n",
       " 'explicit is better': 29,\n",
       " 'face of ambiguity': 30,\n",
       " 'first unless you': 31,\n",
       " 'flat is better': 32,\n",
       " 'great idea let': 33,\n",
       " 'hard to explain': 34,\n",
       " 'honking great idea': 35,\n",
       " 'idea let do': 36,\n",
       " 'if the implementation': 37,\n",
       " 'implementation is easy': 38,\n",
       " 'implementation is hard': 39,\n",
       " 'in the face': 40,\n",
       " 'is better than': 41,\n",
       " 'is easy to': 42,\n",
       " 'is hard to': 43,\n",
       " 'is often better': 44,\n",
       " 'it bad idea': 45,\n",
       " 'it may be': 46,\n",
       " 'let do more': 47,\n",
       " 'may be good': 48,\n",
       " 'may not be': 49,\n",
       " 'more of those': 50,\n",
       " 'namespaces are one': 51,\n",
       " 'never is often': 52,\n",
       " 'never pass silently': 53,\n",
       " 'not be obvious': 54,\n",
       " 'now is better': 55,\n",
       " 'obvious at first': 56,\n",
       " 'obvious way to': 57,\n",
       " 'of ambiguity refuse': 58,\n",
       " 'often better than': 59,\n",
       " 'one and preferably': 60,\n",
       " 'one honking great': 61,\n",
       " 'one obvious way': 62,\n",
       " 'only one obvious': 63,\n",
       " 'practicality beats purity': 64,\n",
       " 'preferably only one': 65,\n",
       " 'refuse the temptation': 66,\n",
       " 'should be one': 67,\n",
       " 'should never pass': 68,\n",
       " 'simple is better': 69,\n",
       " 'sparse is better': 70,\n",
       " 'special cases aren': 71,\n",
       " 'special enough to': 72,\n",
       " 'temptation to guess': 73,\n",
       " 'than right now': 74,\n",
       " 'that way may': 75,\n",
       " 'the face of': 76,\n",
       " 'the implementation is': 77,\n",
       " 'the temptation to': 78,\n",
       " 'there should be': 79,\n",
       " 'to break the': 80,\n",
       " 'to do it': 81,\n",
       " 'to explain it': 82,\n",
       " 'unless explicitly silenced': 83,\n",
       " 'unless you re': 84,\n",
       " 'way may not': 85,\n",
       " 'way to do': 86,\n",
       " 'you re dutch': 87}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect2.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "counts1 = vect2.transform(lines).toarray()\n",
    "print(counts1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<19x88 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 97 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_word = vect2.transform(lines)\n",
    "bag_of_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
